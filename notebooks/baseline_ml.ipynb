{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Classical Models for ANLI R2\n",
    "\n",
    "This notebook trains three classical ML baseline models for Natural Language Inference on the ANLI Round 2 dataset:\n",
    "\n",
    "### Models Included:\n",
    "1. **Logistic Regression**\n",
    "2. **Linear SVM (LinearSVC)**\n",
    "3. **XGBoost Classifier**\n",
    "\n",
    "### Workflow:\n",
    "1. Load dataset (`src/data_loading.py`)\n",
    "2. Preprocess text → combine Premise + Hypothesis\n",
    "3. Train classical models\n",
    "4. Evaluate on validation & test sets\n",
    "5. Save each model\n",
    "6. Produce comparison metrics table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup\n",
    "\n",
    "_Assumes this notebook is running locally and `src/` folder exists._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH updated: /Users/ashmitgupta/Desktop/anli-nli-project\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"PYTHONPATH updated:\", project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ashmitgupta/Desktop/anli-nli-project/src/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "import src.evaluation\n",
    "print(src.evaluation.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashmitgupta/Desktop/anli-nli-project/anli_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ashmitgupta/Desktop/anli-nli-project/anli_env/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Local imports\n",
    "from src.data_loading import load_anli_r2, LABEL2NAME\n",
    "from src.preprocessing import combine_premise_hypothesis\n",
    "from src.evaluation import evaluate_and_print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "    num_rows: 45460\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val, test = load_anli_r2()\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Inputs (X and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [combine_premise_hypothesis(x) for x in train]\n",
    "y_train = train[\"label\"]\n",
    "\n",
    "X_val = [combine_premise_hypothesis(x) for x in val]\n",
    "y_val = val[\"label\"]\n",
    "\n",
    "X_test = [combine_premise_hypothesis(x) for x in test]\n",
    "y_test = test[\"label\"]\n",
    "\n",
    "target_names = [LABEL2NAME[i] for i in sorted(LABEL2NAME.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------\n",
    "## 4. Model 1 — Logistic Regression (TF-IDF)\n",
    "# -----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "logreg_clf = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=100_000, ngram_range=(1, 2))),\n",
    "    (\"logreg\", LogisticRegression(max_iter=300, class_weight=\"balanced\", n_jobs=-1))\n",
    "])\n",
    "\n",
    "print(\"Training Logistic Regression...\")\n",
    "logreg_clf.fit(X_train, y_train)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression — Validation =====\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.33      0.37      0.35       334\n",
      "      neutral       0.33      0.29      0.31       333\n",
      "contradiction       0.33      0.32      0.33       333\n",
      "\n",
      "     accuracy                           0.33      1000\n",
      "    macro avg       0.33      0.33      0.33      1000\n",
      " weighted avg       0.33      0.33      0.33      1000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[124 103 107]\n",
      " [123  98 112]\n",
      " [128  97 108]]\n",
      "\n",
      "===== Logistic Regression — Test =====\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.32      0.36      0.34       334\n",
      "      neutral       0.39      0.36      0.37       333\n",
      "contradiction       0.32      0.30      0.31       333\n",
      "\n",
      "     accuracy                           0.34      1000\n",
      "    macro avg       0.34      0.34      0.34      1000\n",
      " weighted avg       0.34      0.34      0.34      1000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[120  98 116]\n",
      " [113 119 101]\n",
      " [142  91 100]]\n",
      "Saved: baseline_logreg.joblib\n"
     ]
    }
   ],
   "source": [
    "logreg_val_preds = logreg_clf.predict(X_val)\n",
    "evaluate_and_print(y_val, logreg_val_preds, target_names, prefix=\"Logistic Regression — Validation\")\n",
    "\n",
    "logreg_test_preds = logreg_clf.predict(X_test)\n",
    "evaluate_and_print(y_test, logreg_test_preds, target_names, prefix=\"Logistic Regression — Test\")\n",
    "\n",
    "joblib.dump(logreg_clf, \"baseline_logreg.joblib\")\n",
    "print(\"Saved: baseline_logreg.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------\n",
    "## 5. Model 2 — Linear SVM (LinearSVC)\n",
    "# -----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinearSVC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashmitgupta/Desktop/anli-nli-project/anli_env/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "svm_clf = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=100_000, ngram_range=(1, 2))),\n",
    "    (\"svm\", LinearSVC())\n",
    "])\n",
    "\n",
    "print(\"Training LinearSVC...\")\n",
    "svm_clf.fit(X_train, y_train)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Linear SVM — Validation =====\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.32      0.36      0.34       334\n",
      "      neutral       0.35      0.43      0.38       333\n",
      "contradiction       0.35      0.23      0.27       333\n",
      "\n",
      "     accuracy                           0.34      1000\n",
      "    macro avg       0.34      0.34      0.33      1000\n",
      " weighted avg       0.34      0.34      0.33      1000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[121 142  71]\n",
      " [119 143  71]\n",
      " [133 125  75]]\n",
      "\n",
      "===== Linear SVM — Test =====\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.34      0.37      0.35       334\n",
      "      neutral       0.39      0.49      0.44       333\n",
      "contradiction       0.32      0.20      0.25       333\n",
      "\n",
      "     accuracy                           0.36      1000\n",
      "    macro avg       0.35      0.36      0.35      1000\n",
      " weighted avg       0.35      0.36      0.35      1000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[124 128  82]\n",
      " [106 164  63]\n",
      " [136 129  68]]\n",
      "Saved: baseline_svm.joblib\n"
     ]
    }
   ],
   "source": [
    "svm_val_preds = svm_clf.predict(X_val)\n",
    "evaluate_and_print(y_val, svm_val_preds, target_names, prefix=\"Linear SVM — Validation\")\n",
    "\n",
    "svm_test_preds = svm_clf.predict(X_test)\n",
    "evaluate_and_print(y_test, svm_test_preds, target_names, prefix=\"Linear SVM — Test\")\n",
    "\n",
    "joblib.dump(svm_clf, \"baseline_svm.joblib\")\n",
    "print(\"Saved: baseline_svm.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------\n",
    "## 6. Model 3 — XGBoost Classifier\n",
    "# -----------------------------\n",
    "XGBoost cannot directly use sparse TF-IDF matrices, so we convert them to dense arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectors ready.\n"
     ]
    }
   ],
   "source": [
    "tfidf_vec = TfidfVectorizer(max_features=10_000, ngram_range=(1, 2))\n",
    "tfidf_vec.fit(X_train)\n",
    "\n",
    "X_train_tfidf = tfidf_vec.transform(X_train).toarray()\n",
    "X_val_tfidf   = tfidf_vec.transform(X_val).toarray()\n",
    "X_test_tfidf  = tfidf_vec.transform(X_test).toarray()\n",
    "\n",
    "print(\"TF-IDF vectors ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost (300 trees)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=3,   \n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost (300 trees)...\")\n",
    "xgb_clf.fit(X_train_tfidf, y_train)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== XGBoost — Validation =====\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.35      0.34      0.35       334\n",
      "      neutral       0.36      0.58      0.45       333\n",
      "contradiction       0.37      0.17      0.23       333\n",
      "\n",
      "     accuracy                           0.36      1000\n",
      "    macro avg       0.36      0.36      0.34      1000\n",
      " weighted avg       0.36      0.36      0.34      1000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[114 173  47]\n",
      " [ 94 192  47]\n",
      " [115 163  55]]\n",
      "\n",
      "===== XGBoost — Test =====\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.39      0.40      0.40       334\n",
      "      neutral       0.39      0.59      0.47       333\n",
      "contradiction       0.40      0.17      0.24       333\n",
      "\n",
      "     accuracy                           0.39      1000\n",
      "    macro avg       0.39      0.39      0.37      1000\n",
      " weighted avg       0.39      0.39      0.37      1000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[135 152  47]\n",
      " [ 95 198  40]\n",
      " [112 164  57]]\n",
      "Saved: baseline_xgboost.joblib (model + TF-IDF vectorizer)\n"
     ]
    }
   ],
   "source": [
    "xgb_val_preds = xgb_clf.predict(X_val_tfidf)\n",
    "evaluate_and_print(y_val, xgb_val_preds, target_names, prefix=\"XGBoost — Validation\")\n",
    "\n",
    "xgb_test_preds = xgb_clf.predict(X_test_tfidf)\n",
    "evaluate_and_print(y_test, xgb_test_preds, target_names, prefix=\"XGBoost — Test\")\n",
    "\n",
    "joblib.dump((xgb_clf, tfidf_vec), \"baseline_xgboost.joblib\")\n",
    "print(\"Saved: baseline_xgboost.joblib (model + TF-IDF vectorizer)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------\n",
    "## 7. Compare Model Performances\n",
    "# -----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Val Accuracy  Test Accuracy\n",
       "0  Logistic Regression         0.330          0.339\n",
       "1           Linear SVM         0.339          0.356\n",
       "2              XGBoost         0.361          0.390"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\",\n",
    "        \"Linear SVM\",\n",
    "        \"XGBoost\"\n",
    "    ],\n",
    "    \"Val Accuracy\": [\n",
    "        accuracy_score(y_val, logreg_val_preds),\n",
    "        accuracy_score(y_val, svm_val_preds),\n",
    "        accuracy_score(y_val, xgb_val_preds)\n",
    "    ],\n",
    "    \"Test Accuracy\": [\n",
    "        accuracy_score(y_test, logreg_test_preds),\n",
    "        accuracy_score(y_test, svm_test_preds),\n",
    "        accuracy_score(y_test, xgb_test_preds)\n",
    "    ]\n",
    "})\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
